{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3782728,"sourceType":"datasetVersion","datasetId":1692},{"sourceId":10930710,"sourceType":"datasetVersion","datasetId":6784332}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T08:05:46.130234Z","iopub.execute_input":"2025-03-07T08:05:46.130458Z","iopub.status.idle":"2025-03-07T08:05:46.169427Z","shell.execute_reply.started":"2025-03-07T08:05:46.130439Z","shell.execute_reply":"2025-03-07T08:05:46.168668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's load the dataset\ndf = pd.read_csv(\"/kaggle/input/million-headlines/abcnews-date-text.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T02:26:16.874088Z","iopub.execute_input":"2025-03-03T02:26:16.874396Z","iopub.status.idle":"2025-03-03T02:26:18.507403Z","shell.execute_reply.started":"2025-03-03T02:26:16.874375Z","shell.execute_reply":"2025-03-03T02:26:18.506741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's see a bit of the data we are dealing with\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T02:26:20.897433Z","iopub.execute_input":"2025-03-03T02:26:20.897838Z","iopub.status.idle":"2025-03-03T02:26:20.925444Z","shell.execute_reply.started":"2025-03-03T02:26:20.897812Z","shell.execute_reply":"2025-03-03T02:26:20.924353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Renaming a column to better reference it in our DataFrame\ndf = df.rename(columns={\"headline_text\": \"text\"})\ndf = df.drop(columns=[\"publish_date\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T02:35:46.328107Z","iopub.execute_input":"2025-03-03T02:35:46.328400Z","iopub.status.idle":"2025-03-03T02:35:46.394528Z","shell.execute_reply.started":"2025-03-03T02:35:46.328377Z","shell.execute_reply":"2025-03-03T02:35:46.393813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's check out the types of data are in our dataframe\ndf.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T03:06:52.115093Z","iopub.execute_input":"2025-03-03T03:06:52.115409Z","iopub.status.idle":"2025-03-03T03:06:52.121999Z","shell.execute_reply.started":"2025-03-03T03:06:52.115388Z","shell.execute_reply":"2025-03-03T03:06:52.121037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Although the DataFrame does not have labels for sentiment analysis, we can create one ourselves with huggingface\nfrom transformers import pipeline\n\nsnmt_classifier = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T16:59:25.291140Z","iopub.execute_input":"2025-03-08T16:59:25.291400Z","iopub.status.idle":"2025-03-08T16:59:50.818674Z","shell.execute_reply.started":"2025-03-08T16:59:25.291363Z","shell.execute_reply":"2025-03-08T16:59:50.818013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentiment = {\"sentiment\": [result['label'] for result in results]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T03:41:19.282203Z","iopub.execute_input":"2025-03-03T03:41:19.282580Z","iopub.status.idle":"2025-03-03T03:41:19.286451Z","shell.execute_reply.started":"2025-03-03T03:41:19.282550Z","shell.execute_reply":"2025-03-03T03:41:19.285624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentiment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T03:41:25.652864Z","iopub.execute_input":"2025-03-03T03:41:25.653147Z","iopub.status.idle":"2025-03-03T03:41:25.658434Z","shell.execute_reply.started":"2025-03-03T03:41:25.653126Z","shell.execute_reply":"2025-03-03T03:41:25.657644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#We define a function to get sentiment of a piece of text\ndef get_sentiment_batch(examples):\n    results = snmt_classifier(examples[\"text\"])\n    return {\"sentiment\": [result['label'] for result in results]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T03:36:11.262474Z","iopub.execute_input":"2025-03-03T03:36:11.262794Z","iopub.status.idle":"2025-03-03T03:36:11.267079Z","shell.execute_reply.started":"2025-03-03T03:36:11.262772Z","shell.execute_reply":"2025-03-03T03:36:11.266172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Convert the DataFrame to a Hugging Face Dataset\nfrom datasets import Dataset\n\nnews_dataset = Dataset.from_pandas(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T03:36:11.806533Z","iopub.execute_input":"2025-03-03T03:36:11.806808Z","iopub.status.idle":"2025-03-03T03:36:12.326803Z","shell.execute_reply.started":"2025-03-03T03:36:11.806784Z","shell.execute_reply":"2025-03-03T03:36:12.325909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_from_disk\n\n#labeled_dataset = news_dataset.map(get_sentiment_batch, batched=True)\n\nlabeled_dataset = load_from_disk(\"/kaggle/input/labeled-headlines/datasets/labeled\", keep_in_memory=True)\nlabeled_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:41:22.365435Z","iopub.execute_input":"2025-03-10T04:41:22.365868Z","iopub.status.idle":"2025-03-10T04:41:22.391078Z","shell.execute_reply.started":"2025-03-10T04:41:22.365829Z","shell.execute_reply":"2025-03-10T04:41:22.389923Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8cafb97b1217>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#labeled_dataset = news_dataset.map(get_sentiment_batch, batched=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabeled_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/labeled-headlines/datasets/labeled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlabeled_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_to_fs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2207\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Directory {dataset_path} not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2208\u001b[0m     if fs.isfile(posixpath.join(dataset_path, config.DATASET_INFO_FILENAME)) and fs.isfile(\n\u001b[1;32m   2209\u001b[0m         \u001b[0mposixpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_STATE_JSON_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Directory /kaggle/input/labeled-headlines/datasets/labeled not found"],"ename":"FileNotFoundError","evalue":"Directory /kaggle/input/labeled-headlines/datasets/labeled not found","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"#Before we do anything else, let's split our dataset into training and test \nsplit_dataset = labeled_dataset.train_test_split(test_size=.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:40:53.284028Z","iopub.status.idle":"2025-03-10T04:40:53.284295Z","shell.execute_reply":"2025-03-10T04:40:53.284189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Converting back to a DataFrame to perform analysis about the dataset we labeled\nsplit_dataset.set_format(type=\"pandas\")\ndf = split_dataset[\"train\"][:]\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's analyze our train set to get a better glimpse of what we are dealing with\nimport matplotlib.pyplot as plt\n\ndf[\"sentiment\"].value_counts(ascending=True).plot.barh()\nplt.title(\"Frequency of Classes\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's create a boxplot to see the number of words in each sentiment\ndf[\"Words Per Headline\"] = df[\"text\"].str.split().apply(len)\ndf.boxplot(\"Words Per Headline\", by=\"sentiment\", grid=False, showfliers=False, color=\"Black\")\nplt.suptitle(\"\")\nplt.xlabel(\"\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T04:38:26.298655Z","iopub.execute_input":"2025-03-04T04:38:26.298938Z","iopub.status.idle":"2025-03-04T04:38:30.324925Z","shell.execute_reply.started":"2025-03-04T04:38:26.298885Z","shell.execute_reply":"2025-03-04T04:38:30.323746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Saving our datasets for later\n#labeled_dataset.save_to_disk(\"/kaggle/working/datasets/labeled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T04:38:33.494000Z","iopub.execute_input":"2025-03-04T04:38:33.494278Z","iopub.status.idle":"2025-03-04T04:38:33.497530Z","shell.execute_reply.started":"2025-03-04T04:38:33.494255Z","shell.execute_reply":"2025-03-04T04:38:33.496826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#We are done with DataFrames, let's reset our split dataset\nsplit_dataset.reset_format()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T04:46:38.412725Z","iopub.execute_input":"2025-03-04T04:46:38.413051Z","iopub.status.idle":"2025-03-04T04:46:38.417192Z","shell.execute_reply.started":"2025-03-04T04:46:38.413025Z","shell.execute_reply":"2025-03-04T04:46:38.416335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Next, we need to tokenize our text into numerical inputs\nfrom transformers import AutoTokenizer\n\nmodel_ckpt = \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T08:07:34.355910Z","iopub.execute_input":"2025-03-07T08:07:34.356208Z","iopub.status.idle":"2025-03-07T08:07:34.544431Z","shell.execute_reply.started":"2025-03-07T08:07:34.356188Z","shell.execute_reply":"2025-03-07T08:07:34.543791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Creating a function to tokenize a batch of text\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T08:07:39.341486Z","iopub.execute_input":"2025-03-07T08:07:39.341802Z","iopub.status.idle":"2025-03-07T08:07:39.345657Z","shell.execute_reply.started":"2025-03-07T08:07:39.341754Z","shell.execute_reply":"2025-03-07T08:07:39.344718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Map the split dataset to encode the text\nheadlines_encoded = split_dataset.map(tokenize, batched=True, batch_size=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T05:03:49.342336Z","iopub.execute_input":"2025-03-04T05:03:49.342704Z","iopub.status.idle":"2025-03-04T05:04:52.911917Z","shell.execute_reply.started":"2025-03-04T05:03:49.342676Z","shell.execute_reply":"2025-03-04T05:04:52.910531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check out the input_ids and attention_masks we have created!\nheadlines_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T05:05:06.096162Z","iopub.execute_input":"2025-03-04T05:05:06.096513Z","iopub.status.idle":"2025-03-04T05:05:06.101830Z","shell.execute_reply.started":"2025-03-04T05:05:06.096484Z","shell.execute_reply":"2025-03-04T05:05:06.100802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Now to encode the sentiment labels\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(headlines_encoded[\"train\"][\"sentiment\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T05:11:06.984803Z","iopub.execute_input":"2025-03-04T05:11:06.985124Z","iopub.status.idle":"2025-03-04T05:11:08.225248Z","shell.execute_reply.started":"2025-03-04T05:11:06.985099Z","shell.execute_reply":"2025-03-04T05:11:08.224519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's map the encoder to our entire dataset\nheadlines_encoded= headlines_encoded.map(\n        lambda examples: {\"sentiment\": label_encoder.transform(examples[\"sentiment\"])},\n        batched= True,\n        batch_size = None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T05:15:33.423529Z","iopub.execute_input":"2025-03-04T05:15:33.423857Z","iopub.status.idle":"2025-03-04T05:15:35.888081Z","shell.execute_reply.started":"2025-03-04T05:15:33.423836Z","shell.execute_reply":"2025-03-04T05:15:35.887366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking out some of our labeled sentiments\nheadlines_encoded[\"train\"][\"sentiment\"][:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T05:26:10.108174Z","iopub.execute_input":"2025-03-04T05:26:10.108491Z","iopub.status.idle":"2025-03-04T05:26:10.490099Z","shell.execute_reply.started":"2025-03-04T05:26:10.108464Z","shell.execute_reply":"2025-03-04T05:26:10.489448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Save/Load our model currently so we don't change it completely for the different methods to train our model\nheadlines_encoded = load_from_disk(\"/kaggle/working/datasets/encoded\", keep_in_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T08:14:21.009250Z","iopub.execute_input":"2025-03-07T08:14:21.009584Z","iopub.status.idle":"2025-03-07T08:14:22.442707Z","shell.execute_reply.started":"2025-03-07T08:14:21.009560Z","shell.execute_reply":"2025-03-07T08:14:22.441733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Method 1: Trying to oversample the minority class with SMOTE to offset neutral imbalance\n\"\"\"\nfrom imblearn.over_sampling import SMOTE\nfrom datasets import Dataset\n\n#Separate the features and labels\nX_train = headlines_encoded[\"train\"][\"input_ids\"]\ny_train = headlines_encoded[\"train\"][\"sentiment\"]\nattn_mask = headlines_encoded[\"train\"][\"attention_mask\"]\n#Initialize SMOTE\noversampler = SMOTE(sampling_strategy=\"minority\")\n\n#Resample our data\nX_resampled, y_resampled, attn_resampled = oversampler.fit_resample(X_train, y_train)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:19:57.007974Z","iopub.execute_input":"2025-03-04T06:19:57.008286Z","iopub.status.idle":"2025-03-04T06:19:57.013390Z","shell.execute_reply.started":"2025-03-04T06:19:57.008263Z","shell.execute_reply":"2025-03-04T06:19:57.012586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Update our dataset\n#resampled_df = pd.DataFrame({\"input_ids\": X_resampled, \"sentiment\": y_resampled })\n#resampled_dataset = Dataset.from_pandas(resampled_df)\n#headlines_encoded[\"train\"] = resampled_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:20:07.662128Z","iopub.execute_input":"2025-03-04T06:20:07.662444Z","iopub.status.idle":"2025-03-04T06:20:07.665763Z","shell.execute_reply.started":"2025-03-04T06:20:07.662399Z","shell.execute_reply":"2025-03-04T06:20:07.665036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Now we can finally start training our text classifier\nfrom transformers import AutoModel\nimport torch\n\nmodel_ckpt = \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModel.from_pretrained(model_ckpt).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:23:51.985540Z","iopub.execute_input":"2025-03-04T06:23:51.985872Z","iopub.status.idle":"2025-03-04T06:23:53.018801Z","shell.execute_reply.started":"2025-03-04T06:23:51.985845Z","shell.execute_reply":"2025-03-04T06:23:53.018112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Function to extract the last hidden states for the headlines\n\ndef extract_hidden_states(batch):\n    inputs = {k:v.to(device) for k,v in batch.items()\n                             if k in tokenizer.model_input_names}\n    #Extract last hidden states\n    with torch.no_grad():\n        last_hidden_state = model(**inputs).last_hidden_state\n    #Return vector for CLS token\n    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:35:24.053724Z","iopub.execute_input":"2025-03-04T06:35:24.054034Z","iopub.status.idle":"2025-03-04T06:35:24.058528Z","shell.execute_reply.started":"2025-03-04T06:35:24.054010Z","shell.execute_reply":"2025-03-04T06:35:24.057612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Convert our dataset into torch tensors to be used in our model\nheadlines_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"sentiment\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T06:35:25.172463Z","iopub.execute_input":"2025-03-04T06:35:25.172784Z","iopub.status.idle":"2025-03-04T06:35:25.177523Z","shell.execute_reply.started":"2025-03-04T06:35:25.172755Z","shell.execute_reply":"2025-03-04T06:35:25.176648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Now we can finally extract the hidden weights to be mapped in one go\nheadlines_hidden = headlines_encoded.map(extract_hidden_states, batched=True, batch_size=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:22:46.493157Z","iopub.execute_input":"2025-03-10T04:22:46.493516Z","iopub.status.idle":"2025-03-10T04:22:46.522911Z","shell.execute_reply.started":"2025-03-10T04:22:46.493452Z","shell.execute_reply":"2025-03-10T04:22:46.521604Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ee2d9f978d95>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Now we can finally extract the hidden weights to be mapped in one go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mheadlines_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheadlines_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'headlines_encoded' is not defined"],"ename":"NameError","evalue":"name 'headlines_encoded' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"#Let's save/load our hidden state dataset\nfrom datasets import load_from_disk\n\n#headlines_hidden.save_to_disk(\"/kaggle/working/datasets/hidden\")\nheadlines_hidden = load_from_disk(\"/kaggle/input/labeled-headlines/datasets/hidden\", keep_in_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:57:26.798613Z","iopub.execute_input":"2025-03-10T04:57:26.798980Z","iopub.status.idle":"2025-03-10T04:57:37.784548Z","shell.execute_reply.started":"2025-03-10T04:57:26.798947Z","shell.execute_reply":"2025-03-10T04:57:37.783843Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Create a feature matrix\nimport numpy as np\n\nX_train = np.array(headlines_hidden[\"train\"][\"hidden_state\"])\nX_test  = np.array(headlines_hidden[\"test\"][\"hidden_state\"])\ny_train = np.array(headlines_hidden[\"train\"][\"sentiment\"])\ny_test  = np.array(headlines_hidden[\"test\"][\"sentiment\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:57:58.685403Z","iopub.execute_input":"2025-03-10T04:57:58.686003Z","iopub.status.idle":"2025-03-10T04:58:05.046685Z","shell.execute_reply.started":"2025-03-10T04:57:58.685966Z","shell.execute_reply":"2025-03-10T04:58:05.045656Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:43:29.758745Z","iopub.execute_input":"2025-03-10T04:43:29.758994Z","iopub.status.idle":"2025-03-10T04:43:29.764657Z","shell.execute_reply.started":"2025-03-10T04:43:29.758974Z","shell.execute_reply":"2025-03-10T04:43:29.763887Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((995347, 768), (248837, 768))"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"!pip install umap-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T02:58:42.607115Z","iopub.execute_input":"2025-03-10T02:58:42.607485Z","iopub.status.idle":"2025-03-10T02:58:47.905990Z","shell.execute_reply.started":"2025-03-10T02:58:42.607426Z","shell.execute_reply":"2025-03-10T02:58:47.904985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's now train the model with logistic regression\nfrom sklearn.linear_model import LogisticRegression\n\nlr_clf = LogisticRegression(max_iter=1000)\nlr_clf.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T04:59:02.647546Z","iopub.execute_input":"2025-03-10T04:59:02.647933Z","iopub.status.idle":"2025-03-10T05:17:25.395761Z","shell.execute_reply.started":"2025-03-10T04:59:02.647901Z","shell.execute_reply":"2025-03-10T05:17:25.394519Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#Let's see how logistic regression scores on the test set\nlr_clf.score(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:19:03.210257Z","iopub.execute_input":"2025-03-10T05:19:03.210962Z","iopub.status.idle":"2025-03-10T05:19:03.790315Z","shell.execute_reply.started":"2025-03-10T05:19:03.210927Z","shell.execute_reply":"2025-03-10T05:19:03.789455Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0.9994494387892476"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#Using dummy classifier to establish a baseline\nfrom sklearn.dummy import DummyClassifier\n\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:19:06.929202Z","iopub.execute_input":"2025-03-10T05:19:06.929546Z","iopub.status.idle":"2025-03-10T05:19:07.043293Z","shell.execute_reply.started":"2025-03-10T05:19:06.929515Z","shell.execute_reply":"2025-03-10T05:19:07.042476Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DummyClassifier(strategy='most_frequent')","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#Find Dummy Classifier score\ndummy_clf.score(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:19:08.550388Z","iopub.execute_input":"2025-03-10T05:19:08.550671Z","iopub.status.idle":"2025-03-10T05:19:08.565073Z","shell.execute_reply.started":"2025-03-10T05:19:08.550649Z","shell.execute_reply":"2025-03-10T05:19:08.564176Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0.7841800053850513"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}